<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LISTEN: Lexical vs. Acoustic Emotion Benchmark</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>

<body>
    <nav class="navbar">
        <div class="container">
            <div class="nav-brand">
                <i class="fas fa-headphones"></i> LISTEN
            </div>
            <div class="nav-links">
                <a href="#overview">Overview</a>
                <a href="#leaderboard">Leaderboard</a>
                <a href="#visualizations">Results</a>
                <a href="#interactive-challenge" class="game-link">
                    <i class="fas fa-brain"></i> Do You Listen?
                </a>
                <a href="#experiments">Experiments</a>
                <a href="#examples">Examples</a>
                <a href="#citation">Citation</a>
                <a href="https://github.com/DeliJingyiC/LISTEN" target="_blank">
                    <i class="fab fa-github"></i> GitHub
                </a>
            </div>
        </div>
    </nav>

    <header class="hero">
        <div class="container hero-container">
            <div class="hero-content">
                <h1>Do Audio LLMs <span class="flip-words"><span class="flip-word">LISTEN</span><span
                            class="flip-word">Transcribe</span></span>?</h1>
                <p class="subtitle">Measuring Lexical vs. Acoustic Emotion Cues Reliance in Audio LLMs</p>
                <p class="description">
                    A comprehensive benchmark revealing that most audio-language models over-rely on text and miss
                    critical prosodic cues‚Äîespecially when words and tone conflict.
                </p>
                <div class="hero-buttons">
                    <a href="https://github.com/DeliJingyiC/LISTEN" class="btn btn-primary" target="_blank">
                        <i class="fab fa-github"></i> View on GitHub
                    </a>
                    <a href="https://huggingface.co/datasets/VibeCheck1/LISTEN_full" class="btn btn-secondary"
                        target="_blank">
                        <i class="fas fa-database"></i> Dataset
                    </a>
                    <a href="#citation" class="btn btn-secondary">
                        <i class="fas fa-quote-right"></i> Cite
                    </a>
                </div>
            </div>
            <div class="hero-visual">
                <img src="background_image4.png" alt="LISTEN Benchmark Illustration" class="hero-chart">
            </div>
        </div>
    </header>

    <!-- In-page Interactive Challenge (Flip between Text and Audio) -->
    <section id="interactive-challenge" class="section-featured">
        <div class="container">
            <div class="challenge-header">
                <h2>Do You Listen?</h2>
                <p class="challenge-subtitle">Test your emotion recognition skills in this challenge</p>
            </div>

            <div class="game-embed">
                <div class="game-progress">
                    <div class="progress-indicator">
                        <span class="current-round">Round <span id="currentRound">1</span></span>
                        <span class="total-rounds">of <span id="totalRounds">6</span></span>
                    </div>
                    <div class="progress-bar-game">
                        <div class="progress-fill-game" id="progressFillGame"></div>
                    </div>
                </div>

                <div class="flip-card-container" id="flipCardContainer">
                    <div class="flip-card" id="flipCard">
                        <div class="flip-card-front">
                            <div class="card-type-badge">üìù Text Question</div>
                            <div class="question-content">
                                <p class="question-text" id="questionText">"Yeah, it's a great time to be alive, isn't
                                    it?"</p>
                            </div>
                            <p class="question-prompt">What emotion is being expressed?</p>
                            <div class="emotion-options" id="emotionOptions"></div>
                        </div>

                        <div class="flip-card-back">
                            <div class="card-type-badge">üéµ Audio Question</div>
                            <div class="question-content">
                                <div class="audio-player-embed">
                                    <i class="fas fa-volume-up audio-icon-large"></i>
                                    <audio controls id="audioElement" class="audio-control">
                                        <source id="audioSource" src="" type="audio/wav">
                                    </audio>
                                    <p class="audio-instruction">Listen carefully to the tone</p>
                                </div>
                            </div>
                            <p class="question-prompt">What emotion do you hear?</p>
                            <div class="emotion-options" id="emotionOptionsBack"></div>
                        </div>
                    </div>
                </div>

                <div class="answer-feedback" id="answerFeedback" style="display: none;">
                    <div class="feedback-content">
                        <div class="correct-answer-display">
                            <span class="feedback-label">Correct Answer:</span>
                            <span class="feedback-value" id="correctAnswer">Happiness</span>
                        </div>
                        <div class="ai-comparison">
                            <h4>AI Models Performance:</h4>
                            <div class="ai-results-grid" id="aiResultsGrid"></div>
                        </div>
                        <div class="insight-message" id="insightMessage"></div>
                        <button class="btn-next-round" id="btnNextRound" onclick="nextQuestion()">Next Question <i
                                class="fas fa-arrow-right"></i></button>
                    </div>
                </div>

                <div class="final-results" id="finalResults" style="display: none;">
                    <div class="results-content">
                        <div class="trophy-display">
                            <i class="fas fa-trophy"></i>
                        </div>
                        <h3>Challenge Complete!</h3>
                        <div class="score-display">
                            <div class="user-score">
                                <span class="score-label">Your Score</span>
                                <span class="score-number" id="userScore">0/6</span>
                            </div>
                        </div>
                        <div class="ai-scores-comparison" id="aiScoresComparison"></div>
                        <div class="performance-breakdown">
                            <h4>Your Performance</h4>
                            <div class="perf-bars">
                                <div class="perf-bar">
                                    <span class="perf-label">Text Questions</span>
                                    <div class="perf-bar-container">
                                        <div class="perf-bar-fill" id="textPerf"></div>
                                    </div>
                                    <span class="perf-percent" id="textPercent">0%</span>
                                </div>
                                <div class="perf-bar">
                                    <span class="perf-label">Audio Questions</span>
                                    <div class="perf-bar-container">
                                        <div class="perf-bar-fill acoustic" id="audioPerf"></div>
                                    </div>
                                    <span class="perf-percent" id="audioPercent">0%</span>
                                </div>
                            </div>
                        </div>
                        <div class="results-message" id="resultsMessage"></div>
                        <div class="results-actions">
                            <button class="btn-restart" onclick="restartChallenge()"><i class="fas fa-redo"></i> Try
                                Again</button>
                            <a href="#leaderboard" class="btn-view-full">View Full Benchmark <i
                                    class="fas fa-arrow-right"></i></a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <style>
        .section-featured {
            background: #222222;
            color: white;
            padding: 5rem 0;
        }

        .challenge-header {
            text-align: center;
            margin-bottom: 3rem;
        }

        .challenge-header h2 {
            font-size: 2.5rem;
            color: white;
            margin-bottom: 1rem;
        }

        .challenge-subtitle {
            font-size: 1.2rem;
            color: rgba(255, 255, 255, 0.8);
        }

        .game-embed {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 1rem;
            padding: 2.5rem;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }

        .game-progress {
            margin-bottom: 2rem;
        }

        .progress-indicator {
            display: flex;
            justify-content: center;
            gap: 0.5rem;
            margin-bottom: 0.75rem;
            color: #6B6B6B;
            font-weight: 600;
        }

        .progress-bar-game {
            background: #F8F7F5;
            height: 8px;
            border-radius: 1rem;
            overflow: hidden;
            border: 1px solid #E2E0DD;
        }

        .progress-fill-game {
            background: linear-gradient(90deg, #B08BBB, #C7B8EA);
            height: 100%;
            transition: width 0.5s ease;
        }

        .flip-card-container {
            perspective: 1000px;
            min-height: 400px;
            margin-bottom: 2rem;
        }

        .flip-card {
            position: relative;
            width: 100%;
            height: 100%;
            transition: transform 0.8s;
            transform-style: preserve-3d;
        }

        .flip-card.flipped {
            transform: rotateY(180deg);
        }

        .flip-card-front,
        .flip-card-back {
            position: absolute;
            width: 100%;
            backface-visibility: hidden;
            -webkit-backface-visibility: hidden;
        }

        .flip-card-back {
            transform: rotateY(180deg);
        }

        .card-type-badge {
            display: inline-block;
            background: #F0F4FF;
            color: #1A1A1A;
            padding: 0.5rem 1rem;
            border-radius: 2rem;
            font-weight: 600;
            margin-bottom: 1.5rem;
            font-size: 0.9rem;
        }

        .question-content {
            background: #F8F7F5;
            padding: 2rem;
            border-radius: 1rem;
            margin-bottom: 1.5rem;
            border: 2px solid #E2E0DD;
            min-height: 150px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .question-text {
            font-size: 1.5rem;
            font-weight: 600;
            color: #1A1A1A;
            font-style: italic;
            text-align: center;
            line-height: 1.6;
        }

        .audio-player-embed {
            text-align: center;
            width: 100%;
        }

        .audio-icon-large {
            font-size: 3rem;
            color: #B08BBB;
            margin-bottom: 1rem;
            display: block;
        }

        .audio-control {
            width: 100%;
            max-width: 400px;
            margin: 1rem auto;
            display: block;
        }

        .audio-instruction {
            color: #6B6B6B;
            font-size: 0.95rem;
            margin-top: 0.5rem;
        }

        .question-prompt {
            font-size: 1.1rem;
            font-weight: 600;
            color: #1A1A1A;
            margin-bottom: 1.5rem;
            text-align: center;
        }

        .emotion-options {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
            gap: 0.75rem;
        }

        .emotion-btn {
            background: #F8F7F5;
            border: 2px solid #E2E0DD;
            padding: 0.875rem;
            border-radius: 0.5rem;
            font-weight: 600;
            color: #1A1A1A;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.95rem;
        }

        .emotion-btn:hover {
            background: #F0F4FF;
            border-color: #B08BBB;
            transform: translateY(-2px);
        }

        .emotion-btn.selected {
            background: #2E2E2E;
            color: white;
            border-color: #2E2E2E;
        }

        .answer-feedback {
            animation: fadeIn 0.5s ease;
        }

        .feedback-content {
            background: #F8F7F5;
            padding: 2rem;
            border-radius: 1rem;
            border: 2px solid #E2E0DD;
        }

        .correct-answer-display {
            background: linear-gradient(135deg, #4E9A77, #3A7A5D);
            color: white;
            padding: 1.25rem;
            border-radius: 0.75rem;
            text-align: center;
            margin-bottom: 1.5rem;
        }

        .feedback-label {
            display: block;
            font-size: 0.9rem;
            opacity: 0.9;
            margin-bottom: 0.5rem;
        }

        .feedback-value {
            font-size: 1.5rem;
            font-weight: 700;
        }

        .ai-comparison h4 {
            color: #1A1A1A;
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .ai-results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 0.75rem;
            margin-bottom: 1.5rem;
        }

        .ai-result-item {
            background: white;
            padding: 0.875rem;
            border-radius: 0.5rem;
            border-left: 4px solid #E2E0DD;
        }

        .ai-result-item.correct {
            border-left-color: #4E9A77;
            background: #F0FDF4;
        }

        .ai-result-item.incorrect {
            border-left-color: #B66161;
            background: #FEF2F2;
        }

        .ai-name-small {
            font-weight: 600;
            font-size: 0.85rem;
            color: #1A1A1A;
            margin-bottom: 0.25rem;
        }

        .ai-guess-small {
            font-size: 0.9rem;
            color: #6B6B6B;
        }

        .insight-message {
            background: #F0F4FF;
            padding: 1rem;
            border-radius: 0.5rem;
            border-left: 4px solid #B08BBB;
            color: #1A1A1A;
            line-height: 1.6;
            margin-bottom: 1.5rem;
        }

        .btn-next-round {
            background: #222222;
            color: white;
            border: 2px solid #222222;
            padding: 0.875rem 2rem;
            border-radius: 0.5rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin: 0 auto;
        }

        .btn-next-round:hover {
            background: transparent;
            color: #222222;
        }

        .final-results {
            animation: fadeIn 0.8s ease;
        }

        .results-content {
            text-align: center;
        }

        .trophy-display {
            width: 100px;
            height: 100px;
            background: #FEF9F0;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto 1.5rem;
            border: 2px solid #E2E0DD;
        }

        .trophy-display i {
            font-size: 2.5rem;
            color: #C8A44B;
        }

        .results-content h3 {
            font-size: 2rem;
            color: #1A1A1A;
            margin-bottom: 2rem;
        }

        .score-display {
            margin-bottom: 2rem;
        }

        .user-score {
            display: flex;
            flex-direction: column;
            gap: 0.5rem;
        }

        .score-label {
            font-size: 1rem;
            color: #6B6B6B;
        }

        .score-number {
            font-size: 3rem;
            font-weight: 700;
            color: #B08BBB;
        }

        .ai-scores-comparison {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
            gap: 1rem;
            margin-bottom: 2rem;
        }

        .ai-score-card {
            background: #F8F7F5;
            padding: 1rem;
            border-radius: 0.5rem;
            border: 1px solid #E2E0DD;
        }

        .ai-score-card.winner {
            border: 2px solid #C8A44B;
            background: #FEF9F0;
        }

        .ai-model-name {
            font-size: 0.85rem;
            color: #6B6B6B;
            margin-bottom: 0.5rem;
        }

        .ai-score-value {
            font-size: 1.5rem;
            font-weight: 700;
            color: #1A1A1A;
        }

        .performance-breakdown {
            background: #F8F7F5;
            padding: 1.5rem;
            border-radius: 0.75rem;
            margin-bottom: 1.5rem;
        }

        .performance-breakdown h4 {
            color: #1A1A1A;
            margin-bottom: 1rem;
        }

        .perf-bars {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .perf-bar {
            display: grid;
            grid-template-columns: 140px 1fr 60px;
            align-items: center;
            gap: 1rem;
        }

        .perf-label {
            font-weight: 600;
            color: #1A1A1A;
            font-size: 0.9rem;
        }

        .perf-bar-container {
            background: white;
            height: 32px;
            border-radius: 0.5rem;
            overflow: hidden;
            border: 1px solid #E2E0DD;
        }

        .perf-bar-fill {
            background: linear-gradient(90deg, #2E2E2E, #4A4A4A);
            height: 100%;
            transition: width 1s ease;
        }

        .perf-bar-fill.acoustic {
            background: linear-gradient(90deg, #B08BBB, #C7B8EA);
        }

        .perf-percent {
            font-weight: 600;
            color: #1A1A1A;
            text-align: right;
        }

        .results-message {
            background: #FEF9F0;
            padding: 1.5rem;
            border-radius: 0.75rem;
            border: 2px solid #C8A44B;
            margin-bottom: 1.5rem;
            line-height: 1.7;
            color: #1A1A1A;
        }

        .results-actions {
            display: flex;
            gap: 1rem;
            justify-content: center;
            flex-wrap: wrap;
        }

        .btn-restart,
        .btn-view-full {
            padding: 0.875rem 1.75rem;
            border-radius: 0.5rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            text-decoration: none;
        }

        .btn-restart {
            background: #222222;
            color: white;
            border: 2px solid #222222;
        }

        .btn-restart:hover {
            background: transparent;
            color: #222222;
        }

        .btn-view-full {
            background: transparent;
            color: #222222;
            border: 2px solid #E2E0DD;
        }

        .btn-view-full:hover {
            border-color: #222222;
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @media (max-width: 768px) {
            .game-embed {
                padding: 1.5rem;
            }

            .question-text {
                font-size: 1.2rem;
            }

            .emotion-options {
                grid-template-columns: repeat(2, 1fr);
            }

            .perf-bar {
                grid-template-columns: 1fr;
                gap: 0.5rem;
            }

            .perf-percent {
                text-align: left;
            }
        }
    </style>

    <script>
        const gameQuestions = [
            { type: "text", text: "You are cruising for a bruising.  You are in so much trouble.", correct: "anger", emotions: ["disgust", "neutral", "ridicule", "frustration", "sadness", "anger", "excitement", "fear", "surprise", "happiness"], aiPredictions: { "Gemini 2.5 Pro": { guess: "anger", correct: true }, "Qwen3-Omni": { guess: "anger", correct: true }, "Gemini 2.5 Flash": { guess: "anger", correct: true } }, insight: "These words burns with anger. You can feel the threat, right?" },
            { type: "audio", audio: "Ses01F_impro05_F021.wav", correct: "anger", emotions: ["disgust", "neutral", "ridicule", "frustration", "sadness", "anger", "excitement", "fear", "surprise", "happiness"], aiPredictions: { "Gemini 2.5 Pro": { guess: "anger", correct: true }, "Qwen3-Omni": { guess: "anger", correct: true }, "Gemini 2.5 Flash": { guess: "anger", correct: true } }, insight: "The angry tone is unmistakable in this audio clip." },

            { type: "text", text: "Great! Now we can do laundry all night. All night laundry!", correct: "happiness", emotions: ["disgust", "neutral", "ridicule", "frustration", "sadness", "anger", "excitement", "fear", "surprise", "happiness"], aiPredictions: { "Gemini 2.5 Pro": { guess: "frustration", correct: false }, "Qwen3-Omni": { guess: "happiness", correct: true }, "Gemini 2.5 Flash": { guess: "excitement", correct: false } }, insight: "This text is full of positivity!" },
            { type: "audio", audio: "2_155_u.wav", correct: "anger", emotions: ["disgust", "neutral", "ridicule", "frustration", "sadness", "anger", "excitement", "fear", "surprise", "happiness"], aiPredictions: { "Gemini 2.5 Pro": { guess: "anger", correct: true }, "Qwen3-Omni": { guess: "excitement", correct: false }, "Gemini 2.5 Flash": { guess: "ridicule", correct: false } }, insight: "Hear that edge? The tone carries pure anger, loud and tense. Now is not positive at all. The acoustic cues weigh heavier than the lexical cues." },


            { type: "text", text: "Yeah, sure, what a wonderful idea!", correct: "excitement", emotions: ["disgust", "neutral", "ridicule", "frustration", "sadness", "anger", "excitement", "fear", "surprise", "happiness"], aiPredictions: { "Gemini 2.5 Pro": { guess: "excitement", correct: true }, "Qwen3-Omni": { guess: "excitement", correct: true }, "Gemini 2.5 Flash": { guess: "excitement", correct: true } }, insight: "what a wonderful idea is exciting!" },
            { type: "audio", audio: "1_8407_u.wav", correct: "frustration", emotions: ["disgust", "neutral", "ridicule", "frustration", "sadness", "anger", "excitement", "fear", "surprise", "happiness"], aiPredictions: { "Gemini 2.5 Pro": { guess: "disgust", correct: false }, "Qwen3-Omni": { guess: "frustration", correct: true }, "Gemini 2.5 Flash": { guess: "frustration", correct: true } }, insight: "The voice sounds frustrated, again, the acoustic cues weigh heavier than the lexical cues." }
        ];

        let currentQuestion = 0;
        let userAnswers = [];
        let aiScores = { "Gemini 2.5 Pro": 0, "Qwen3-Omni": 0, "Gemini 2.5 Flash": 0 };

        function initGame() {
            const totalEl = document.getElementById('totalRounds');
            if (!totalEl) return;
            totalEl.textContent = gameQuestions.length;
            loadQuestion();
        }

        function loadQuestion() {
            const question = gameQuestions[currentQuestion];
            document.getElementById('currentRound').textContent = currentQuestion + 1;
            const progress = ((currentQuestion + 1) / gameQuestions.length) * 100;
            document.getElementById('progressFillGame').style.width = progress + '%';
            const flipCard = document.getElementById('flipCard');
            const isAudio = question.type === 'audio';
            if (isAudio) {
                flipCard.classList.add('flipped');
                document.getElementById('audioSource').src = question.audio;
                document.getElementById('audioElement').load();
                renderEmotionButtons('emotionOptionsBack', question.emotions, isAudio);
            } else {
                flipCard.classList.remove('flipped');
                document.getElementById('questionText').textContent = `"${question.text}"`;
                renderEmotionButtons('emotionOptions', question.emotions, isAudio);
            }
            document.getElementById('answerFeedback').style.display = 'none';
            document.getElementById('finalResults').style.display = 'none';
            document.getElementById('flipCardContainer').style.display = '';
        }

        function renderEmotionButtons(containerId, emotions, isAudio) {
            const container = document.getElementById(containerId);
            container.innerHTML = '';
            emotions.forEach(emotion => {
                const btn = document.createElement('button');
                btn.className = 'emotion-btn';
                btn.textContent = emotion.charAt(0).toUpperCase() + emotion.slice(1);
                btn.onclick = () => selectAnswer(emotion, btn, isAudio);
                container.appendChild(btn);
            });
        }

        function selectAnswer(emotion, btn, isAudio) {
            const containerId = isAudio ? 'emotionOptionsBack' : 'emotionOptions';
            document.querySelectorAll(`#${containerId} .emotion-btn`).forEach(b => b.classList.remove('selected'));
            btn.classList.add('selected');
            setTimeout(() => { checkAnswer(emotion); }, 300);
        }

        function checkAnswer(userAnswer) {
            const question = gameQuestions[currentQuestion];
            const isCorrect = userAnswer === question.correct;
            userAnswers.push({ type: question.type, correct: isCorrect });
            Object.keys(question.aiPredictions).forEach(model => { if (question.aiPredictions[model].correct) { aiScores[model]++; } });
            showFeedback(question, isCorrect);
        }

        function showFeedback(question, userCorrect) {
            document.getElementById('correctAnswer').textContent = question.correct.charAt(0).toUpperCase() + question.correct.slice(1);
            const aiGrid = document.getElementById('aiResultsGrid');
            aiGrid.innerHTML = '';
            Object.keys(question.aiPredictions).forEach(model => {
                const pred = question.aiPredictions[model];
                const div = document.createElement('div');
                div.className = `ai-result-item ${pred.correct ? 'correct' : 'incorrect'}`;
                div.innerHTML = `<div class="ai-name-small">${model}</div><div class="ai-guess-small">${pred.guess.charAt(0).toUpperCase() + pred.guess.slice(1)}</div>`;
                aiGrid.appendChild(div);
            });
            document.getElementById('insightMessage').textContent = question.insight;
            document.getElementById('answerFeedback').style.display = 'block';
            if (currentQuestion === gameQuestions.length - 1) {
                const btn = document.getElementById('btnNextRound');
                btn.textContent = 'See Results';
                btn.innerHTML = 'See Results <i class="fas fa-trophy"></i>';
            }
        }

        function nextQuestion() {
            currentQuestion++;
            if (currentQuestion < gameQuestions.length) {
                loadQuestion();
            } else {
                showResults();
            }
        }

        function showResults() {
            document.getElementById('flipCardContainer').style.display = 'none';
            document.getElementById('answerFeedback').style.display = 'none';
            document.getElementById('finalResults').style.display = 'block';
            const correctCount = userAnswers.filter(a => a.correct).length;
            document.getElementById('userScore').textContent = `${correctCount}/${gameQuestions.length}`;
            const aiGrid = document.getElementById('aiScoresComparison');
            aiGrid.innerHTML = '';
            const maxScore = Math.max(...Object.values(aiScores), correctCount);
            Object.entries(aiScores).forEach(([model, score]) => {
                const div = document.createElement('div');
                div.className = `ai-score-card ${score === maxScore ? 'winner' : ''}`;
                div.innerHTML = `<div class="ai-model-name">${model}</div><div class="ai-score-value">${score}/${gameQuestions.length}</div>`;
                aiGrid.appendChild(div);
            });
            const textCorrect = userAnswers.filter(a => a.type === 'text' && a.correct).length;
            const audioCorrect = userAnswers.filter(a => a.type === 'audio' && a.correct).length;
            const textTotal = userAnswers.filter(a => a.type === 'text').length;
            const audioTotal = userAnswers.filter(a => a.type === 'audio').length;
            const textPercent = textTotal ? (textCorrect / textTotal) * 100 : 0;
            const audioPercent = audioTotal ? (audioCorrect / audioTotal) * 100 : 0;
            setTimeout(() => {
                document.getElementById('textPerf').style.width = textPercent + '%';
                document.getElementById('audioPerf').style.width = audioPercent + '%';
                document.getElementById('textPercent').textContent = Math.round(textPercent) + '%';
                document.getElementById('audioPercent').textContent = Math.round(audioPercent) + '%';
            }, 300);
            let message = '';
            if (correctCount === gameQuestions.length) {
                message = 'üèÜ <strong>Perfect Score!</strong> You beat all the AI models!';
            } else if (correctCount >= maxScore) {
                message = 'üéâ <strong>Impressive!</strong> You matched or beat the best AI models.';
            } else {
                message = `You scored ${correctCount}/${gameQuestions.length}. ${audioPercent > textPercent ? "You're stronger with audio!" : "You're stronger with text!"}`;
            }
            document.getElementById('resultsMessage').innerHTML = message;
        }

        function restartChallenge() {
            currentQuestion = 0;
            userAnswers = [];
            aiScores = { "Gemini 2.5 Pro": 0, "Qwen3-Omni": 0, "Baichuan-Omni": 0 };
            const btn = document.getElementById('btnNextRound');
            if (btn) btn.innerHTML = 'Next Question <i class="fas fa-arrow-right"></i>';
            loadQuestion();
        }

        document.addEventListener('DOMContentLoaded', initGame);
    </script>

    <section id="overview" class="section">
        <div class="container">
            <h2>Overview</h2>
            <div class="overview-content">
                <p>
                    <strong>LISTEN</strong> is a novel benchmark designed to evaluate multimodal audio-language models
                    on their ability to understand and distinguish between lexical and acoustic emotional cues in
                    speech.
                    The benchmark consists of four main experiment types:
                </p>
                <div class="experiment-cards">
                    <div class="card">
                        <div class="card-icon">1</div>
                        <h3>Neutral-Text</h3>
                        <p>Emotion recognition with neutral transcriptions across modalities</p>
                        <span class="badge">3 variants</span>
                    </div>
                    <div class="card">
                        <div class="card-icon">2</div>
                        <h3>Emotion-Matched</h3>
                        <p>Lexical and acoustic cues convey the same emotion</p>
                        <span class="badge">3 variants</span>
                    </div>
                    <div class="card">
                        <div class="card-icon">3</div>
                        <h3>Emotion-Mismatched</h3>
                        <p>Lexical and acoustic cues convey conflicting emotions</p>
                        <span class="badge">3 variants</span>
                    </div>
                    <div class="card">
                        <div class="card-icon">4</div>
                        <h3>Paralinguistic</h3>
                        <p>Non-verbal vocalizations without lexical content</p>
                        <span class="badge">1 variant</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="leaderboard" class="section section-gray">
        <div class="container">
            <h2>Leaderboard</h2>
            <p class="section-description">
                Performance of state-of-the-art audio-language models on the LISTEN benchmark.
                Click on column headers to sort.
            </p>

            <div class="leaderboard-controls">
                <div class="filter-group">
                    <label>Filter by Experiment:</label>
                    <select id="experimentFilter">
                        <option value="all">All Experiments</option>
                        <option value="exp1">Experiment 1 (Neutral-Text)</option>
                        <option value="exp2">Experiment 2 (Emotion-Matched)</option>
                        <option value="exp3">Experiment 3 (Emotion-Mismatched)</option>
                        <option value="exp4">Experiment 4 (Paralinguistic)</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Filter by Metric:</label>
                    <select id="metricFilter">
                        <option value="accuracy">Accuracy</option>
                        <option value="weighted_accuracy">Weighted Accuracy</option>
                        <option value="uar">UAR</option>
                        <option value="macro_f1">Macro F1</option>
                        <option value="micro_f1">Micro F1</option>
                    </select>
                </div>
                <div class="search-group">
                    <input type="text" id="modelSearch" placeholder="Search models...">
                </div>
            </div>

            <div class="table-container">
                <table id="leaderboardTable" class="leaderboard-table">
                    <thead>
                        <tr>
                            <th data-sort="rank">Rank</th>
                            <th data-sort="model">Model</th>
                            <th data-sort="type">Type</th>
                            <th data-sort="avg" class="sortable active">Overall Average <i class="fas fa-sort-down"></i>
                            </th>
                            <th data-sort="exp1_text">Neutral-Text (Text)</th>
                            <th data-sort="exp1_audio">Neutral-Text (Audio)</th>
                            <th data-sort="exp1_both">Neutral-Text (Both)</th>
                            <th data-sort="exp2_text">Emotion-Matched (Text)</th>
                            <th data-sort="exp2_audio">Emotion-Matched (Audio)</th>
                            <th data-sort="exp2_both">Emotion-Matched (Both)</th>
                            <th data-sort="exp3_text">Emotion-Mismatched (Text)</th>
                            <th data-sort="exp3_audio">Emotion-Mismatched (Audio)</th>
                            <th data-sort="exp3_both">Emotion-Mismatched (Both)</th>
                            <th data-sort="exp4_audio">Paralinguistic (Audio)</th>
                        </tr>
                    </thead>
                    <tbody id="leaderboardBody">
                        <!-- Data will be populated by JavaScript -->
                    </tbody>
                </table>
            </div>

            <div class="leaderboard-notes">
                <h3>Notes:</h3>
                <ul>
                    <li><strong>Overall Average</strong>: Mean accuracy across all audio and text+audio results from the
                        four experimental conditions (7 modalities total, excluding text-only)</li>
                    <li><strong>Weighted Accuracy</strong>: Accuracy weighted by class distribution</li>
                    <li><strong>UAR</strong>: Unweighted Average Recall (mean of per-class recalls)</li>
                    <li><strong>Macro F1</strong>: Unweighted mean of per-class F1 scores</li>
                    <li><strong>Micro F1</strong>: F1 score calculated globally across all classes</li>
                    <li><strong>Baseline Models</strong>: Uniform Guess and Majority Guess are not ranked with other
                        models</li>
                </ul>
            </div>
        </div>
    </section>

    <section id="visualizations" class="section">
        <div class="container">
            <h2>Performance Visualization</h2>
            <p class="section-description">
                Detailed model performance across different modalities and experimental conditions
            </p>

            <div class="visualization-single">
                <div class="viz-card-large">
                    <img src="hero_radar.png" alt="Detailed radar chart showing model performance across all modalities"
                        class="viz-image-large">
                    <p class="viz-caption">Comprehensive comparison of model performance across seven modalities:
                        Neutral-Text (Text/Audio), Emotion-Matched (Text/Audio), Emotion-Mismatched (Text/Audio), and
                        Paralinguistic (Audio). Gemini 2.5 Pro demonstrates the most balanced performance, while
                        Qwen3-Omni-30B excels in Emotion-Matched conditions.</p>
                </div>
            </div>
        </div>
    </section>



    <section id="experiments" class="section">
        <div class="container">
            <h2>Experiment Details</h2>
            <div class="experiment-details">
                <div class="detail-card">
                    <h3><span class="exp-number">1</span> Neutral-Text</h3>
                    <p><strong>Task:</strong> Emotion recognition with neutral transcriptions</p>
                    <p><strong>Variants:</strong></p>
                    <ul>
                        <li><code>Text</code>: Neutral text transcription only</li>
                        <li><code>Audio</code>: Audio with emotional prosody</li>
                        <li><code>Text+Audio</code>: Both modalities (neutral text + emotional audio)</li>
                    </ul>
                    <p><strong>Purpose:</strong> Assess if models can recognize emotion from prosody when text is
                        neutral</p>
                </div>

                <div class="detail-card">
                    <h3><span class="exp-number">2</span> Emotion-Matched</h3>
                    <p><strong>Task:</strong> Emotion recognition when lexical and acoustic cues agree</p>
                    <p><strong>Variants:</strong></p>
                    <ul>
                        <li><code>Text</code>: Emotional text only</li>
                        <li><code>Audio</code>: Audio with matching emotional prosody</li>
                        <li><code>Text+Audio</code>: Both modalities with matching emotions</li>
                    </ul>
                    <p><strong>Purpose:</strong> Baseline performance when both modalities provide consistent emotional
                        information</p>
                </div>

                <div class="detail-card">
                    <h3><span class="exp-number">3</span> Emotion-Mismatched</h3>
                    <p><strong>Task:</strong> Emotion recognition when lexical and acoustic cues conflict</p>
                    <p><strong>Variants:</strong></p>
                    <ul>
                        <li><code>Text</code>: Emotional text (conflicting with audio emotion)</li>
                        <li><code>Audio</code>: Audio with conflicting emotional prosody</li>
                        <li><code>Text+Audio</code>: Both modalities with conflicting emotions</li>
                    </ul>
                    <p><strong>Purpose:</strong> Test whether models rely more on lexical or acoustic cues when they
                        conflict</p>
                </div>

                <div class="detail-card">
                    <h3><span class="exp-number">4</span> Paralinguistic</h3>
                    <p><strong>Task:</strong> Emotion recognition from non-verbal vocalizations</p>
                    <p><strong>Variants:</strong></p>
                    <ul>
                        <li><code>Audio</code>: Non-verbal sounds (laughter, sighs, gasps, etc.)</li>
                    </ul>
                    <p><strong>Purpose:</strong> Evaluate understanding of purely acoustic emotional cues without
                        lexical content</p>
                </div>
            </div>
        </div>
    </section>

    <section id="examples" class="section section-gray">
        <div class="container">
            <h2>Condition Examples</h2>
            <p class="section-description">
                Representative examples from each experimental condition showing the task format and model predictions
            </p>

            <div class="examples-container">
                <!-- Neutral-Text Examples -->
                <div class="example-card">
                    <div class="example-header neutral-text">
                        <span class="example-icon">1</span>
                        <h3>Neutral-Text (Text-only)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_7c8b53fb</code>
                        </div>
                        <div class="example-field">
                            <strong>Transcription:</strong> <em>"Kids are talking by the door."</em>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Read the transcription and classify the emotion. Based on the
                            content of this text, what emotion would the person likely be feeling?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. anger | B. fear | C. disgust | D. neutral | E. sadness | F.
                            surprise | G. calm | H.
                            happiness
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth:</strong> <span class="badge-neutral">neutral</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-correct">D (neutral) ‚úì</span>
                            </div>
                        </div>
                        <div class="example-note">
                            The model correctly identifies the statement's emotion (neutral) from lexical cues alone.
                        </div>
                    </div>
                </div>

                <!-- Emotion-Matched Example -->
                <div class="example-card">
                    <div class="example-header emotion-matched">
                        <span class="example-icon">2</span>
                        <h3>Emotion-Matched (Text-only)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_9b76ea7d</code>
                        </div>
                        <div class="example-field">
                            <strong>Transcription:</strong> <em>"What the hell is this?"</em>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Read the transcription and classify the emotion. From the semantic
                            content alone, what emotion is being expressed?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. neutral | B. sadness | C. excitement |D. frustration | E. fear
                            | F. disgust | G. happiness | H. anger | I. surprise
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth:</strong> <span class="badge-frustration">frustration</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-incorrect">D (neutral) ‚úó</span>
                            </div>
                        </div>
                        <div class="example-note">
                            The model misclassified an explicitly frustration utterance as neutral, illustrating
                            overgeneralization across semantically related negative emotions.
                        </div>
                    </div>
                </div>

                <!-- Emotion-Mismatched Text Example -->
                <div class="example-card">
                    <div class="example-header emotion-mismatched">
                        <span class="example-icon">3</span>
                        <h3>Emotion-Mismatched (Text-only)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_955399e0</code>
                        </div>
                        <div class="example-field">
                            <strong>Transcription:</strong> <em>"You're right, the party's fantastic. Please, tell me
                                more. I haven't heard enough about it all week because hearing about that never gets
                                old!"</em>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Read the transcription and classify the emotion. What emotion is
                            conveyed by the words in this statement?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. surprise | B. excitement
                            | C. sadness | D. disgust | E. fear | F. neutral | G. anger | H. happiness | I. frustration
                            | J. ridicule
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth (Explicit):</strong> <span
                                    class="badge-excitement">excitement</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-correct">B (excitement) ‚úì</span>
                            </div>

                        </div>

                    </div>
                </div>
                <!-- Neutral-Text Audio Example -->
                <div class="example-card">
                    <div class="example-header neutral-text">
                        <span class="example-icon">4</span>
                        <h3>Neutral-Text (Audio-only)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_7c8b53fb</code>
                        </div>
                        <div class="example-field">
                            <strong>Audio:</strong> <code>RAVDESS_train_0333</code>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Listen to the audio and classify the emotion. What emotion is
                            communicated through the speaker's vocal prosody?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. surprise | B. sadness | C. fear | D. anger | E.
                            calm |F. happiness | G. neutral | H. disgust
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth :</strong> <span class="badge-anger">anger</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-correct">D (anger) ‚úó</span>
                            </div>
                        </div>

                    </div>
                </div>
                <!-- Emotion-Matched Audio Example -->
                <div class="example-card">
                    <div class="example-header emotion-matched">
                        <span class="example-icon">5</span>
                        <h3>Emotion-Matched (Audio-only)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_dd0f6e9d</code>
                        </div>
                        <div class="example-field">
                            <strong>Audio:</strong> <code>IEMOCAP_Session5_Ses05M_script01_1b_F030</code>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Listen to the audio and classify the emotion. What emotion is
                            communicated through the speaker's vocal prosody?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. frustration | B. anger | C. neutral | D. excitement | E.
                            happiness |F. surprise | G. disgust | H. fear | I. sadness
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth :</strong> <span class="badge-frustration">frustration</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-correct">D (frustration) ‚úó</span>
                            </div>
                        </div>

                    </div>
                </div>
                <!-- Emotion-Mismatched Audio Example -->
                <div class="example-card">
                    <div class="example-header emotion-mismatched">
                        <span class="example-icon">6</span>
                        <h3>Emotion-Mismatched (Audio-only)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_c52e71d0</code>
                        </div>
                        <div class="example-field">
                            <strong>Audio:</strong> <code>MUStARD_PRO_1_7575_u_3B</code>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Listen to the audio and classify the emotion. What emotion is
                            communicated through the speaker's vocal prosody?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. disgust | B. neutral | C. ridicule | D. frustration | E.
                            sadness | F. anger | G. excitement | H. fear | I.
                            surprise | J. happiness
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth (Implicit):</strong> <span class="badge-anger">anger</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-incorrect">G (excitement) ‚úó</span>
                            </div>
                        </div>

                    </div>
                </div>
                <!-- Neutral-Text Audio Example -->
                <div class="example-card">
                    <div class="example-header neutral-text">
                        <span class="example-icon">7</span>
                        <h3>Neutral-Text (Text+Audio)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_7c8b53fb</code>
                        </div>
                        <div class="example-field">
                            <strong>Audio:</strong> <code>RAVDESS_train_0333</code>
                        </div>
                        <div class="example-field">
                            <strong>Transcription:</strong> <em>"Kids are talking by the door."</em>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Listen to the audio and read the transcription, then classify the
                            emotion. What emotion does the speaker convey through their tone?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. surprise | B. sadness | C. fear | D. anger | E.
                            calm |F. happiness | G. neutral | H. disgust
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth :</strong> <span class="badge-anger">anger</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-correct">D (anger) ‚úó</span>
                            </div>
                        </div>

                    </div>
                </div>
                <!-- Emotion-Matched Audio Example -->
                <div class="example-card">
                    <div class="example-header emotion-matched">
                        <span class="example-icon">8</span>
                        <h3>Emotion-Matched (Text+Audio)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_dd0f6e9d</code>
                        </div>
                        <div class="example-field">
                            <strong>Audio:</strong> <code>IEMOCAP_Session5_Ses05M_script01_1b_F030</code>
                        </div>
                        <div class="example-field">
                            <strong>Transcription:</strong> <em>"What the hell is this?"</em>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Listen to the audio and classify the emotion. What emotion is
                            communicated through the speaker's vocal prosody?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. frustration | B. anger | C. neutral | D. excitement | E.
                            happiness |F. surprise | G. disgust | H. fear | I. sadness
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth :</strong> <span class="badge-frustration">frustration</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-correct">D (frustration) ‚úó</span>
                            </div>
                        </div>

                    </div>
                </div>
                <!-- Emotion-Mismatched Audio Example -->
                <div class="example-card">
                    <div class="example-header emotion-mismatched">
                        <span class="example-icon">9</span>
                        <h3>Emotion-Mismatched (Audio-only)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_c52e71d0</code>
                        </div>
                        <div class="example-field">
                            <strong>Audio:</strong> <code>MUStARD_PRO_1_7575_u_3B</code>
                        </div>
                        <div class="example-field">
                            <strong>Transcription:</strong> <em>"You're right, the party's fantastic. Please, tell me
                                more. I haven't heard enough about it all week because hearing about that never gets
                                old!"</em>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Listen to the audio and classify the emotion. What emotion is
                            communicated through the speaker's vocal prosody?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. disgust | B. neutral | C. ridicule | D. frustration | E.
                            sadness | F. anger | G. excitement | H. fear | I.
                            surprise | J. happiness
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth (Implicit):</strong> <span class="badge-anger">anger</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-incorrect">G (excitement) ‚úó</span>
                            </div>
                        </div>

                    </div>
                </div>

                <!-- Paralinguistic Example -->
                <div class="example-card">
                    <div class="example-header paralinguistic">
                        <span class="example-icon">10</span>
                        <h3>Paralinguistic (Audio-only)</h3>
                    </div>
                    <div class="example-content">
                        <div class="example-field">
                            <strong>Sample ID:</strong> <code>SAMPLE_54df39ff</code>
                        </div>
                        <div class="example-field">
                            <strong>Audio:</strong> <code>IEMOCAP_Session5_Ses05F_impro03_F006</code>
                        </div>
                        <div class="example-field">
                            <strong>Content:</strong> <em>Nonverbal laughter</em>
                        </div>
                        <div class="example-field">
                            <strong>Prompt:</strong> Listen to the audio and classify the emotion. What emotional tone
                            is conveyed by the literal meaning of this statement?
                        </div>
                        <div class="example-choices">
                            <strong>Choices:</strong> A. anger | B. happiness | C. fear | D. sadness | E. surprise | F.
                            frustration | G. excitement | H. disgust | I. neutral
                        </div>
                        <div class="example-results">
                            <div class="result-item">
                                <strong>Ground Truth:</strong> <span class="badge-excitement">excitement</span>
                            </div>
                            <div class="result-item">
                                <strong>Model Prediction:</strong> <span class="badge-incorrect">B (happiness) ‚úó</span>
                            </div>
                        </div>
                        <div class="example-note">
                            The utterance contains only nonverbal laughter. The model incorrectly classifies it as
                            happiness, revealing challenges in distinguishing subtle affective intent from nonverbal
                            vocalizations.
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="citation" class="section section-gray">
        <div class="container">
            <h2>Citation</h2>
            <p>If you use LISTEN in your research, please cite:</p>
            <div class="citation-box">
                <pre><code>@misc{deli2025listen,
  title={Do Audio LLMs Really LISTEN, or Just Transcribe? Measuring Lexical vs. Acoustic Emotion Cues Reliance },
  author={Jingyi Chen, Zhimeng Guo, Jiyun Chun, Pichao Wang, Andrew Perrault, Micha Elsner},
  year={2025},
  publisher={},
  howpublished={\url{https://github.com/DeliJingyiC/LISTEN}},
  note={Dataset available at: \url{https://huggingface.co/datasets/delijingyic/VibeCheck}}
}</code></pre>
                <button class="copy-btn" onclick="copyBibtex()">
                    <i class="fas fa-copy"></i> Copy
                </button>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2025 LISTEN Benchmark. All rights reserved.</p>
            <p>
                <a href="https://github.com/DeliJingyiC/LISTEN" target="_blank">
                    <i class="fab fa-github"></i> GitHub
                </a>
                <a href="https://huggingface.co/datasets/delijingyic/VibeCheck" target="_blank">
                    <i class="fas fa-database"></i> Dataset
                </a>
            </p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>

</html>